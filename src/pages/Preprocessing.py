import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import os
import ast
import nltk
import re

from utils.dbapi import DBapi

db = DBapi()

df = pd.DataFrame(db.get_percentage_documents(per=0.05))

# Variables globales pour simuler les donn√©es
PATH_DATA = "../data/"
RAW_RECIPE = "RAW_recipes_sample.csv"
RAW_INTERACTIONS = "RAW_interactions_sample.csv"


# ---- Page Streamlit ----
st.set_page_config(page_title="Explication du Pr√©traitement", layout="wide")

# --- Titre et Introduction ---
st.title("üåü Explication du Pr√©traitement des Donn√©es")
st.write(
    """
Cette page pr√©sente les √©tapes de pr√©traitement appliqu√©es aux donn√©es, 
ainsi que des visualisations pour mieux comprendre leur impact.
"""
)

# --- Chargement des donn√©es ---
st.header("1Ô∏è‚É£ Chargement des Donn√©es")
st.write(
    """
Les donn√©es brutes sont charg√©es √† partir de fichiers CSV. Voici un aper√ßu des fichiers utilis√©s :
- `RAW_recipes.csv` : Donn√©es des recettes brutes.
- `RAW_interactions.csv` : Interactions des utilisateurs avec les recettes.
"""
)


# Exemple de chargement fictif
@st.cache_data
def load_data(file_name):
    path = os.path.join(PATH_DATA, file_name)
    if os.path.exists(path):
        return pd.read_csv(path)
    else:
        return pd.DataFrame()  # Placeholder si le fichier est manquant


raw_recipes = load_data(RAW_RECIPE)
raw_interactions = load_data(RAW_INTERACTIONS)

# Afficher les donn√©es brutes si elles existent
if not raw_recipes.empty:
    st.write("Exemple de donn√©es brutes :")
    st.dataframe(raw_recipes.head(5))
else:
    st.warning("Fichier RAW_recipes.csv introuvable.")

# --- Transformation des Donn√©es ---
st.header("2Ô∏è‚É£ Transformation des Donn√©es")
st.write(
    """
Plusieurs transformations sont appliqu√©es pour pr√©parer les donn√©es :
1. Conversion de certaines colonnes en listes (`tags`, `steps`, etc.).
2. Fusion des datasets `RAW_recipes` et `RAW_interactions`.
3. Nettoyage des descriptions et des noms.
4. Suppression des valeurs aberrantes.
"""
)

# Exemple visuel avant/apr√®s nettoyage
if not raw_recipes.empty:
    # Conversion fictive
    raw_recipes["submitted"] = pd.to_datetime(
        raw_recipes.get("submitted", pd.Series([]))
    )
    st.write(
        "**Avant conversion de la colonne `submitted` :**",
        raw_recipes["submitted"].dtype,
    )
    st.write("**Apr√®s conversion :**", raw_recipes["submitted"].dtype)

# --- Nettoyage des Donn√©es ---
st.header("3Ô∏è‚É£ Nettoyage des Donn√©es")
st.write(
    """
Les colonnes contenant des valeurs manquantes sont remplac√©es ou supprim√©es :
- La colonne `description` est remplie avec le contenu de `name` si elle est vide.
- Les lignes avec `name` manquant sont supprim√©es.
"""
)

# Visualisation des valeurs manquantes
if not raw_recipes.empty:
    st.write("Visualisation des valeurs manquantes dans les donn√©es brutes :")
    missing_data = raw_recipes.isna().sum()
    fig, ax = plt.subplots(figsize=(8, 4))
    ax.barh(missing_data.index, missing_data.values)
    ax.set_title("Valeurs manquantes par colonne")
    ax.set_xlabel("Nombre de valeurs manquantes")
    st.pyplot(fig)

# --- Suppression des Valeurs Aberrantes ---
st.header("4Ô∏è‚É£ Suppression des Valeurs Aberrantes")
st.write(
    """
Certaines recettes troll ou mal renseign√©es sont supprim√©es :
- Les recettes avec un temps de cuisson excessif.
- Les recettes avec un nombre de steps ou d'ingr√©dients nul.
"""
)

# Exemple fictif
if not raw_recipes.empty:
    cleaned_recipes = raw_recipes[raw_recipes["minutes"] < 300]
    st.write(f"Recettes avant nettoyage : {len(raw_recipes)}")
    st.write(f"Recettes apr√®s nettoyage : {len(cleaned_recipes)}")

# --- Nettoyage des Textes ---
st.header("5Ô∏è‚É£ Nettoyage et Tokenisation des Textes")
st.write(
    """
Les descriptions et noms des recettes sont nettoy√©s et tokenis√©s :
- Suppression des stopwords.
- Tokenisation des phrases en mots.
"""
)

# Afficher des exemples fictifs
example_text = "This is a recipe with a lot of unnecessary words and punctuation!!!"
stopwords = {"this", "is", "a", "and"}
cleaned_text = " ".join(
    [word for word in example_text.lower().split() if word not in stopwords]
)
st.write(f"**Texte brut** : {example_text}")
st.write(f"**Texte nettoy√©** : {cleaned_text}")

# --- Pipeline de Pr√©traitement ---
st.header("6Ô∏è‚É£ Visualisation du Pipeline")
from graphviz import Digraph

dot = Digraph()
dot.node("A", "Chargement")
dot.node("B", "Fusion")
dot.node("C", "Nettoyage")
dot.node("D", "Suppression des Outliers")
dot.node("E", "Tokenisation")
dot.edges(["AB", "BC", "CD", "DE"])
st.graphviz_chart(dot)

# TODO : Faire un tout petit data set csv de 100/200 donn√©es brutes pour expliquer le pretaitement
# TODO : Raconter mieux lhistoire du pretaitement
