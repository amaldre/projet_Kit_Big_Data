import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import os
import ast
import nltk
import re
from utils.dbapi import DBapi
import logging
from utils.load_functions import load_data, load_css
import html


logger = logging.getLogger(os.path.basename(__file__))

# db = DBapi()
# with db:
#     df = pd.DataFrame(db.get_percentage_documents(per=0.0005))

# Variables globales pour simuler les donn√©es
PATH_DATA = "data/"
RAW_RECIPE = "RAW_recipes_sample.csv"
RAW_INTERACTIONS = "RAW_interactions_sample.csv"

# ---- Page Streamlit ----
try:
    st.set_page_config(page_title="Explication Pr√©traitement", layout="wide")
except Exception as e:
    logger.error(f"Erreur lors de la configuration de la page : {e}")
    st.error("Une erreur s'est produite lors de la configuration de la page.")


load_css("src/style.css")

# --- Titre et Introduction ---
st.title("üåü Explication du Pr√©traitement des Donn√©es")
st.write(
    """
Cette page pr√©sente les √©tapes de pr√©traitement appliqu√©es aux donn√©es, 
ainsi que des visualisations pour mieux comprendre leur impact.
"""
)

# --- Chargement des donn√©es ---
st.header("Chargement des Donn√©es")
st.write(
    """
Les donn√©es brutes sont charg√©es √† partir de fichiers CSV. Voici un aper√ßu des fichiers utilis√©s :
- `RAW_recipes.csv` : Donn√©es des recettes brutes.
- `RAW_interactions.csv` : Interactions des utilisateurs avec les recettes.
"""
)


raw_recipes = load_data(PATH_DATA, RAW_RECIPE)
raw_interactions = load_data(PATH_DATA, RAW_INTERACTIONS)

# Afficher les donn√©es brutes si elles existent
if not raw_recipes.empty:
    st.write("Exemple de donn√©es brutes de RAW_recipe:")
    st.dataframe(raw_recipes.head(5))
else:
    st.warning("Fichier RAW_recipes_sample.csv introuvable.")
    logger.warning("RAW_recipes_sample.csv introuvable.")

if not raw_interactions.empty:
    st.write("Exemple de donn√©es brutes de RAW_interactions:")
    st.dataframe(raw_interactions.head(5))
else:
    st.warning("Fichier RAW_interactions_sample.csv introuvable.")
    logger.warning("RAW_interactions_sample.csv introuvable.")

with open("data/Food_data_drawio.html", "r", encoding="utf-8") as f:
    html_string = f.read()

# √âchapper les guillemets du contenu HTML

escaped_html = html.escape(html_string)

# Cr√©er le code HTML de l'iframe avec des styles pour les bords arrondis
iframe_code = f"""
    <iframe srcdoc="{escaped_html}" width="1000" height="800" style="border: 2px solid #55381f; border-radius: 20px; background-color: #ebcdac;"></iframe>
"""

st.components.v1.html(iframe_code, height=820)


# --- Transformation des Donn√©es ---
st.header(" Transformation des Donn√©es")
st.write(
    """
Plusieurs transformations sont appliqu√©es pour pr√©parer les donn√©es :
1. Les datasets doivent √™tre nettoy√©s.
    Pour cela, les recettes avec des valeurs manquantes sont supprim√©es.
    Les recettes avec des valeurs aberrantes sont √©galement supprim√©es.
    Notamment celles avec un temps de cuisson excessif ou un nombre de steps nul.
    Les 'Description' manquantes sont remplies avec le contenu de 'Name' pour combler les vides.
    
2. Les donn√©es de RAW_interactions devaient √™tre fusionn√©es avec RAW_recipes. Pour cela, les deux dataframes ont √©t√© merge sur la colonne `recipe_id`.
Les colonnes de interactions ont √©t√© transform√©es en listes pour faire correspondre chaque recette avec ses interactions, ses commentaires, ses reviews, etc.

3. Fusion des datasets `RAW_recipes` et `RAW_interactions`.

4. Nettoyage des descriptions et des noms.
   Dans le but de r√©aliser un clustering, les descriptions et les noms des recettes sont nettoy√©s et tokenis√©s.
   Les stopwords sont supprim√©s des textes.

"""
)

# Exemple visuel avant/apr√®s nettoyage
if not raw_recipes.empty:
    try:
        raw_recipes["submitted"] = pd.to_datetime(
            raw_recipes.get("submitted", pd.Series([])), errors="coerce"
        )
        st.write(
            "**Avant conversion de la colonne `submitted` :**",
            raw_recipes["tags"].dtype,
        )
        st.write("**Apr√®s conversion :**", raw_recipes["tags"].dtype)
    except Exception as e:
        logger.error(f"Erreur lors de la conversion de la colonne `submitted` : {e}")
        st.error(
            "Erreur lors de la conversion des colonnes. Veuillez v√©rifier vos donn√©es."
        )

# --- Nettoyage des Donn√©es ---
st.header("1Ô∏è‚É£ Nettoyage des Donn√©es")
st.write(
    """
Les colonnes contenant des valeurs manquantes sont remplac√©es ou supprim√©es :
- La colonne `description` est remplie avec le contenu de `name` si elle est vide.
- Les lignes avec `name` manquant sont supprim√©es.
"""
)

# Visualisation des valeurs manquantes
if not raw_recipes.empty:
    try:
        st.write("Visualisation des valeurs manquantes dans les donn√©es brutes :")
        missing_data = raw_recipes.isna().sum()
        fig, ax = plt.subplots(figsize=(8, 4))
        ax.barh(missing_data.index, missing_data.values)
        ax.set_title("Valeurs manquantes par colonne")
        ax.set_xlabel("Nombre de valeurs manquantes")
        st.pyplot(fig)
    except Exception as e:
        logger.error(f"Erreur lors de la visualisation des valeurs manquantes : {e}")
        st.error("Impossible de visualiser les valeurs manquantes.")

# --- Pr√©paration √† la fusion des Donn√©es ---
st.header("2Ô∏è‚É£ Pr√©paration √† la fusion des Donn√©es")
st.write(
    """
Les donn√©es de RAW_interactions sont fusionn√©es avec RAW_recipes :
- Les deux datasets sont joints sur la colonne recipe_id.
- Les colonnes de RAW_interactions sont transform√©es en listes.
"""
)

# --- Visualisation de la Fusion ---
st.header("3Ô∏è‚É£ Visualisation de la Fusion")

# --- Suppression des Valeurs Aberrantes ---
st.header("4Ô∏è‚É£ Suppression des Valeurs Aberrantes")
st.write(
    """
Certaines recettes troll ou mal renseign√©es sont supprim√©es :
- Les recettes avec un temps de cuisson excessif.
- Les recettes avec un nombre de steps ou d'ingr√©dients nul.
"""
)

# Exemple fictif
if not raw_recipes.empty:
    try:
        cleaned_recipes = raw_recipes[raw_recipes["minutes"] < 300]
        st.write(f"Recettes avant nettoyage : {len(raw_recipes)}")
        st.write(f"Recettes apr√®s nettoyage : {len(cleaned_recipes)}")
    except KeyError as e:
        logger.error(f"Erreur : Colonne manquante dans le DataFrame : {e}")
        st.error(
            "Certaines colonnes n√©cessaires pour le nettoyage des donn√©es sont manquantes."
        )
    except Exception as e:
        logger.error(f"Erreur lors de la suppression des valeurs aberrantes : {e}")
        st.error("Une erreur est survenue lors du nettoyage des donn√©es.")

# --- Nettoyage des Textes ---
st.header("5Ô∏è‚É£ Nettoyage et Tokenisation des Textes")
st.write(
    """
Les descriptions et noms des recettes sont nettoy√©s et tokenis√©s :
- Suppression des stopwords.
- Tokenisation des phrases en mots.
"""
)

try:
    example_text = "This is a recipe with a lot of unnecessary words and punctuation!!!"
    stopwords = {"this", "is", "a", "and"}
    cleaned_text = " ".join(
        [word for word in example_text.lower().split() if word not in stopwords]
    )
    st.write(f"**Texte brut** : {example_text}")
    st.write(f"**Texte nettoy√©** : {cleaned_text}")
except Exception as e:
    logger.error(f"Erreur lors du nettoyage des textes : {e}")
    st.error("Impossible de nettoyer les textes.")

# --- Pipeline de Pr√©traitement ---
st.header("6Ô∏è‚É£ Visualisation du Pipeline")
from graphviz import Digraph

try:
    dot = Digraph()
    dot.node("A", "Chargement")
    dot.node("B", "Fusion")
    dot.node("C", "Nettoyage")
    dot.node("D", "Suppression des Outliers")
    dot.node("E", "Tokenisation")
    dot.edges(["AB", "BC", "CD", "DE"])
    st.graphviz_chart(dot)
except Exception as e:
    logger.error(f"Erreur lors de la creation du pipeline visuel : {e}")
    st.error("Impossible de visualiser le pipeline.")

# --- Mise en place d'une base de donn√©es ---
st.header("7Ô∏è‚É£ Mise en place d'une base de donn√©es")
st.write(
    """
Afin de d√©ployer notre application, nous avons mis en place une base de donn√©es MongoDB.
Nous avons alors tent√© d'utiliser MongoDB Atlas.
Pour cela nous avons r√©duit le nombre de colonnes de notre base en supprimant les colonnes inutiles.
Nous avons alors gard√© uniquement les colonnes suivantes car la version gratuite de MongoDB Atlas nous limitait √† 512 Mo de donn√©es :
- recipe_id
- name
- rating
- minutes
- ingredients
- n_steps

Apr√®s avoir cr√©√© notre collection et ins√©r√© nos donn√©es, nous avons pu nous connecter √† notre base de donn√©es via une classe Python cr√©√©e pour l'occasion.
Cependant, la version gratuite de MongoDB Atlas nous a limit√© dans le t√©l√©chargement de nos donn√©es. Le t√©l√©chargement √©tant limit√© √† 10 Go sur une p√©riode glissante de 7 jours, nous avons au cours de nos tests √©puis√© notre quota de t√©l√©chargement.
Nous avons donc abandonn√© l'utilisation de MongoDB Atlas pour une base de donn√©es locale r√©duite √† 120 Mo.
"""
)

# TODO : Raconter mieux lhistoire du pretaitement
