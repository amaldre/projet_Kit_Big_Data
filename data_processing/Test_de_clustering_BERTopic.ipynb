{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.dbapi import DBapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALL_UUID_SUBTYPES', 'Any', 'BSON', 'BSONARR', 'BSONBIN', 'BSONBOO', 'BSONCOD', 'BSONCWS', 'BSONDAT', 'BSONDEC', 'BSONINT', 'BSONLON', 'BSONMAX', 'BSONMIN', 'BSONNUL', 'BSONNUM', 'BSONOBJ', 'BSONOID', 'BSONREF', 'BSONRGX', 'BSONSTR', 'BSONSYM', 'BSONTIM', 'BSONUND', 'Binary', 'BinaryIO', 'CSHARP_LEGACY', 'Callable', 'Code', 'CodecOptions', 'DBRef', 'DEFAULT_CODEC_OPTIONS', 'DatetimeConversion', 'DatetimeMS', 'Decimal128', 'EPOCH_AWARE', 'EPOCH_NAIVE', 'Generator', 'IO', 'Int64', 'InvalidBSON', 'InvalidDocument', 'InvalidStringData', 'Iterator', 'JAVA_LEGACY', 'Mapping', 'MaxKey', 'MinKey', 'MutableMapping', 'NoReturn', 'OLD_UUID_SUBTYPE', 'ObjectId', 'Optional', 'RE_TYPE', 'Regex', 'SON', 'STANDARD', 'Sequence', 'TYPE_CHECKING', 'Timestamp', 'Tuple', 'Type', 'TypeVar', 'UUID_SUBTYPE', 'Union', 'UuidRepresentation', '_BUILT_IN_TYPES', '_CODEC_OPTIONS_TYPE_ERROR', '_ELEMENT_GETTER', '_ENCODERS', '_LIST_NAMES', '_MARKERS', '_PACK_FLOAT', '_PACK_INT', '_PACK_LENGTH_SUBTYPE', '_PACK_LONG', '_PACK_TIMESTAMP', '_T', '_UNPACK_FLOAT_FROM', '_UNPACK_INT', '_UNPACK_INT_FROM', '_UNPACK_LENGTH_SUBTYPE_FROM', '_UNPACK_LONG_FROM', '_UNPACK_TIMESTAMP_FROM', '_USE_C', '__all__', '__annotations__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_abc', '_after_fork', '_array_of_documents_to_buffer', '_bson_to_dict', '_cbson', '_convert_raw_document_lists_to_streams', '_datetime_to_millis', '_decode_all', '_decode_all_selective', '_decode_selective', '_dict_to_bson', '_element_to_bson', '_element_to_dict', '_elements_to_dict', '_encode_binary', '_encode_bool', '_encode_bytes', '_encode_code', '_encode_datetime', '_encode_datetime_ms', '_encode_dbref', '_encode_decimal128', '_encode_float', '_encode_int', '_encode_list', '_encode_long', '_encode_mapping', '_encode_maxkey', '_encode_minkey', '_encode_none', '_encode_objectid', '_encode_regex', '_encode_text', '_encode_timestamp', '_encode_uuid', '_get_array', '_get_binary', '_get_boolean', '_get_c_string', '_get_code', '_get_code_w_scope', '_get_date', '_get_decimal128', '_get_float', '_get_int', '_get_int64', '_get_object', '_get_object_size', '_get_oid', '_get_ref', '_get_regex', '_get_string', '_get_timestamp', '_helpers', '_make_c_string', '_make_c_string_check', '_make_name', '_millis_to_datetime', '_name_value_to_bson', '_raise_unknown_type', '_raw_document_class', '_raw_to_dict', '_typ', '_utf_8_decode', '_utf_8_encode', 'annotations', 'binary', 'cast', 'code', 'codec_options', 'datetime', 'datetime_ms', 'dbref', 'decimal128', 'decode', 'decode_all', 'decode_file_iter', 'decode_iter', 'encode', 'errors', 'gen_list_name', 'get_data_and_view', 'has_c', 'int64', 'is_valid', 'itertools', 'json_util', 'max_key', 'min_key', 'objectid', 'os', 'overload', 'raw_bson', 're', 'regex', 'son', 'struct', 'sys', 'timestamp', 'typings', 'tz_util', 'utc', 'uuid']\n"
     ]
    }
   ],
   "source": [
    "import bson\n",
    "\n",
    "print(dir(bson))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Connexion à la base de données établie avec succès.\n",
      "INFO:root:35485 documents trouvés pour cleaned_description avec un pourcentage de 0.2.\n",
      "INFO:root:Connexion à la base de données fermée.\n"
     ]
    }
   ],
   "source": [
    "db_api = DBapi()\n",
    "with db_api:\n",
    "    result = db_api.get_percentage('cleaned_description',0.2)\n",
    "    df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bertopic import BERTopic\n",
    "\n",
    "from nltk import word_tokenize\n",
    "import os.path as op\n",
    "import re \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "# import the preprocess doc\n",
    "\n",
    "df = df\n",
    "\n",
    "documents = df['cleaned_description'].to_list()\n",
    "\n",
    "# BERTopic (sans n-gram)\n",
    "import hdbscan\n",
    "\n",
    "n_gram_range = (2, 3)\n",
    "\n",
    "hdbscan_model = hdbscan.HDBSCAN(min_cluster_size=100)\n",
    "topic_model = BERTopic(hdbscan_model=hdbscan_model, language=\"english\", nr_topics=10)\n",
    "\n",
    "# TODO : Faire fonctionner BERTopic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "n_topics = 0\n",
    "while n_topics < 5:\n",
    "    topics, probs = topic_model.fit_transform(documents)\n",
    "    n_topics = len(set(topics))\n",
    "df['topic'] = topics\n",
    "df['probs'] = probs\n",
    "    # Afficher les topics les plus fréquents\n",
    "print(topic_model.get_topic_info())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topic_model.get_topic(-1)) \n",
    "# Visualisation des topics\n",
    "topic_model.visualize_topics()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des hiérarchies entre les topics\n",
    "topic_model.visualize_hierarchy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des relations entre les topics\n",
    "topic_model.visualize_barchart(n_words=10, height=400, width=400)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap(n_clusters=7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env_projet_kit_big_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
